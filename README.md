# Импорт Яндекс метрики в clickhouse

## Ссылки на докуменацию

- API передачи параметров <https://yandex.ru/support/metrica/ru>
- Logs API <https://yandex.ru/dev/metrika/ru/logs>
- Официальная библиотека для python <https://clickhouse.com/docs/integrations/python>
  - Используется для импорта файлов метрики, так как тут это удобнее и понятнее, чем в других библиотеках
- Неофициальная библиотека для python <https://clickhouse-driver.readthedocs.io>
  - Используется для всех остальных запросов к кликхаусу 
  - Поддерживает нативный протокол сервера clickhouse. Потенциально для создания отчётов быстрее, чем по HTTP протоколу
- Вся остальная документация clickhouse <https://clickhouse.com/docs>

## Получение токена

Тут написано как создать приложение и получить токен <https://yandex.ru/dev/metrika/ru/intro/authorization>

Дальше просто запульнуть его в `.env` вместе с id счётчика

## Переменные окружения

Всё описано в комментариях в `.env.example`.
Скрипты читают файл `.env`, обычные переменные окружения не влияют на работу.

Если у переменной нет значения - скрипты выкинут ошибку.
Все выставленные значения в `.env.example` - это значения по-умолчанию.
Менять имеет смысл переменные только касающиеся подключения к кликхаусу, метрике, и первую дату.
Остальное наверно лучше не трогать

## Даты

Яндекс запрещает выгружать данные больше чем за год, и максимальная дата - вчерашний день, за сегодня выгрузить метрику нельзя.
С визитами всё в целом ок, но размер данных событий вызывает опасения, поэтому принято решение ограничить выгрузку 90 днями за раз.
При условии, что между запусками скрипта будет проходить меньше 90 дней, метрика довольно быстро должна нагнать текущую дату.

При случае можно период выгрузки настроить переменной окружения `DAY_COUNT`

Файл с датами (`dates.txt` по-умолчанию) лучше не трогать чтобы ничего не сломать

## Ок, у меня есть куча метрики в clickhouse, дальше что?

Запрос на создание виртуальной таблицы mysql в clickhouse
<https://clickhouse.com/docs/engines/table-engines/integrations/mysql>

```dql
CREATE TABLE <virtual_mysql_table> ENGINE = MySQL('<ip>:<port>', <mysql_database>, <mysql_table>, <mysql_user>, <mysql_password>)
```

После объединить стандартным JOIN

```dql
SELECT * FROM <clickhouse_table> JOIN <virtual_mysql_table> ON <clickhouse_table>.<clickhouse_id> = <virtual_mysql_table>.<mysql_id>
```

Виртуальная таблица "обновляется" в реальном времени, пересоздавать не нужно.

Есть так же возможность подрубить сразу всю базу MySQL, а не только одну таблицу
<https://clickhouse.com/docs/engines/database-engines/mysql>

## Импорт метрики других проектов и счётчиков

Для импорта метрики из других счётчиков, скопировать репозиторий и повторить шаги ниже

```sh
export IMPORTER_ARCHIVE="/opt/clickhouse/import.tgz"
export NEW_CLICKHOUSE_IMPORTER="/opt/clickhouse-project-name"
```

```sh
mkdir -p $NEW_CLICKHOUSE_IMPORTER
tar -xzf $IMPORTER_ARCHIVE -C $NEW_CLICKHOUSE_IMPORTER --strip-components=1
python3 -m venv "$NEW_CLICKHOUSE_IMPORTER/.venv"
"$NEW_CLICKHOUSE_IMPORTER/.venv/bin/pip" install -r "$NEW_CLICKHOUSE_IMPORTER/requirements.txt"
(crontab -l ; echo "0 0 * * * $NEW_CLICKHOUSE_IMPORTER/.venv/bin/python $NEW_CLICKHOUSE_IMPORTER/insert.py 1>> $NEW_CLICKHOUSE_IMPORTER/logs 2>> $NEW_CLICKHOUSE_IMPORTER/logs") | crontab -
```

После подредактировать `.env` файл в директории из переменной окружения `NEW_CLICKHOUSE_IMPORTER`.
И crontab подредактировать по вкусу.
Не забыть и про файл дат (`dates.txt` по-умолчанию). В нём только одна строка из двух дат в формате YYYY-MM-DD через запятую.
`init.py` запускать только аккуратно, не забыв, что он дропает базы данных указанные в переменных окружения `MAIN_DATABASE` и `TEMP_DATABASE`.

## Известные приколы API или почему всё так странно работает?

Из-за ограничения на количество символов в поле `fields` при создании запроса логов запрос приходится разбивать на 2 запроса.
Из-за этого сначала скачивается одна часть полей и импортируется во временную таблицу с первичным ключём `visitID` (или `watchID` для событий).
После этого скачивается вторая часть полей и вставляется во вторую временную таблицу с первичным ключём `visitID` (или `watchID` для событий).
После они объединяются `JOIN`'ом и вставляются в конечную таблицу.

Реализованы функции как для загрузки метрики из файлов напрямую, так и через временные таблицы.
Имя первичного ключа задаётся переменными окружения `TEMP_VISIT_KEY` и `TEMP_HIT_KEY` (для визитов и событий соответственно) в формате `<metrika_field_name> <field_type> <clickhouse_field_name>`.
Обычно её менять не нужно, просто на всякий случай, чтобы была кастомизация.

Ещё обнаружилось, что в некоторых полях вместо обычных одинарных кавычек `''` стоят экранированные `\'\'`.
Причина неизвестна, но пришлось считаться с этим и заменять экранированные кавычки на обычные.

В колонке eventsProductType приходит массив, состоящий из строк без кавычек (типа enum, по докам написано UInt8). Не нашёл возможности распарсить это средствами кликхауса, поэтому это перечисление экранируется с помощью регулярных выражений и записывается как строки, а не как UInt8

## Что находится в коде?

### helpers

В директории helpers расположены вспомогательные функции для удобства чтения кода (или типа того).

Также там расположены все возможные и избранные параметры яндекс метрики.
Выгружать меньше, чем ВСЕ параметры имеет не очень много смысла, но можно закастомить их.

### passgen.sh

Нашёл смешной однострочник для генерации паролей и сразу хэша этого пароля (кликхаус проверяет по хэшам).
Пусть лежит.

### init и insert

2 самых главных файла. `init.py` инициализирует всё что нужно для работы: очистка и создание таблиц (надо быть аккуратным чтобы не дропнуть что-то реально важное), определение начальных дат выгрузки.
`insert.py` - основной драйвер, чтение дат, выгрузка метрики во временные таблицы, объединение временных таблиц и вставка в основные таблицы.

### install.sh

Скрипт установки кликхауса

## cloud-init

Скрипт cloud-init находится в файле `clickhouse.sh` без паролей.
Легче всего сгенерировать через `passgen.sh` и вставить вместо `__PASSWORD__` и `__SHA256_PASSWORD__`.

Также не забыть заполнить номер счётчика и ключ к API метрики.
`__METRIKA_COUNTER__` и `__METRIKA_KEY__` соответственно.

